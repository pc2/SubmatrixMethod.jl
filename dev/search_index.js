var documenterSearchIndex = {"docs":
[{"location":"devel/analysis/#Analysis","page":"Analysis","title":"Analysis","text":"","category":"section"},{"location":"devel/analysis/#Density","page":"Analysis","title":"Density","text":"","category":"section"},{"location":"devel/analysis/","page":"Analysis","title":"Analysis","text":"<img src=\"../../assets/imgs/time_vs_density_1000.png\" width=\"80%\"/>\n<br>","category":"page"},{"location":"devel/analysis/","page":"Analysis","title":"Analysis","text":"import Dates\nstring(\"Last run: \", Dates.unix2datetime(mtime(\"../../../analysis/scaling_density/time_vs_density_1000.png\")))","category":"page"},{"location":"devel/analysis/","page":"Analysis","title":"Analysis","text":"<br>\n<img src=\"../../assets/imgs/time_vs_density_10000.png\" width=\"80%\"/>\n<br>","category":"page"},{"location":"devel/analysis/","page":"Analysis","title":"Analysis","text":"import Dates\nstring(\"Last run: \", Dates.unix2datetime(mtime(\"../../../analysis/scaling_density/time_vs_density_10000.png\")))","category":"page"},{"location":"devel/analysis/#Number-of-Threads","page":"Analysis","title":"Number of Threads","text":"","category":"section"},{"location":"devel/analysis/","page":"Analysis","title":"Analysis","text":"<img src=\"../../assets/imgs/time_vs_nthreads_0.001.png\" width=\"80%\"/>\n<br>","category":"page"},{"location":"devel/analysis/","page":"Analysis","title":"Analysis","text":"import Dates\nstring(\"Last run: \", Dates.unix2datetime(mtime(\"../../../analysis/scaling_multithreading/time_vs_nthreads_0.001.png\")))","category":"page"},{"location":"devel/analysis/","page":"Analysis","title":"Analysis","text":"<br>\n<img src=\"../../assets/imgs/time_vs_nthreads_0.0001.png\" width=\"80%\"/>\n<br>","category":"page"},{"location":"devel/analysis/","page":"Analysis","title":"Analysis","text":"import Dates\nstring(\"Last run: \", Dates.unix2datetime(mtime(\"../../../analysis/scaling_multithreading/time_vs_nthreads_0.0001.png\")))","category":"page"},{"location":"devel/analysis/#Matrix-size","page":"Analysis","title":"Matrix size","text":"","category":"section"},{"location":"devel/analysis/","page":"Analysis","title":"Analysis","text":"<img src=\"../../assets/imgs/time_vs_size_0.001.png\" width=\"80%\"/>\n<br>","category":"page"},{"location":"devel/analysis/","page":"Analysis","title":"Analysis","text":"import Dates\nstring(\"Last run: \", Dates.unix2datetime(mtime(\"../../../analysis/scaling_matrixsize/time_vs_size_0.001.png\")))","category":"page"},{"location":"devel/analysis/","page":"Analysis","title":"Analysis","text":"<br>\n<img src=\"../../assets/imgs/time_vs_size_0.0001.png\" width=\"80%\"/>\n<br>","category":"page"},{"location":"devel/analysis/","page":"Analysis","title":"Analysis","text":"import Dates\nstring(\"Last run: \", Dates.unix2datetime(mtime(\"../../../analysis/scaling_matrixsize/time_vs_size_0.0001.png\")))","category":"page"},{"location":"devel/benchmarking/#Benchmarking","page":"Benchmarking","title":"Benchmarking","text":"","category":"section"},{"location":"devel/benchmarking/#Instrumented-Profiling-([TimerOutputs.jl](https://github.com/KristofferC/TimerOutputs.jl))","page":"Benchmarking","title":"Instrumented Profiling (TimerOutputs.jl)","text":"","category":"section"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"By default, the benchmarking facilities are turned off entirely to avoid any performance overhead.","category":"page"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"note: Note\nFor now, only the serial variant, i.e. with launch configuration Serial() (default), can be benchmarked in this way. For Threaded(), you'll likely get lot's of errors. Check out Thread Timers instead.","category":"page"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"Enable the built-in time measurements with SubmatrixMethod.enable_benchmarks().\nRun the functionality that you want to benchmark.\nCall SubmatrixMethod.print_benchmarks() to see the timing results.","category":"page"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"using SubmatrixMethod\nSubmatrixMethod.enable_benchmarks()\nA = sprandsymposdef(1000, 0.01);\nsubmatrix_apply(inv, A);\nsubmatrix_apply(inv, A);\nSubmatrixMethod.print_benchmarks()\nSubmatrixMethod.disable_benchmarks() # hide","category":"page"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"Benchmarks can be reset by calling SubmatrixMethod.reset_benchmarks() or turned off again via SubmatrixMethod.disable_benchmarks().","category":"page"},{"location":"devel/benchmarking/#Thread-Timers","page":"Benchmarking","title":"Thread Timers","text":"","category":"section"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"As an attempt to assess the load-balancing when using multiple threads, Threaded() has a timers option (default: false) which toggles time measurements on individual threads.","category":"page"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"using SubmatrixMethod\nusing ThreadPinning; pinthreads(:compact); # hide\nA = sprandsymposdef(1000, 0.1);\nsubmatrix_apply(inv, A, Threaded(timers=false)); # hide\nsubmatrix_apply(inv, A, Threaded(timers=true));","category":"page"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"If you also load the UnicodePlots.jl package you'll automatically get a nice visual output instead.","category":"page"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"using UnicodePlots\nusing ThreadPinning; pinthreads(:compact); # hide\nsubmatrix_apply(inv, A, Threaded(timers=true));\nsubmatrix_apply(inv, A, Threaded(timers=true, nthreads=5));","category":"page"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"Note that UnicodePlots.jl needs to be installed separately and must be loaded after using SubmatrixMethod.","category":"page"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"You can always (re-)print the timings of the last run via SubmatrixMethod.print_thread_timers(). To access the values themselves, they are stored in SubmatrixMethod.thread_timers[].","category":"page"},{"location":"devel/benchmarking/#Distribution-of-Submatrices-/-Workload","page":"Benchmarking","title":"Distribution of Submatrices / Workload","text":"","category":"section"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"To see how the submatrices have been divided among threads, use the show_distribution option of the Threaded() launch configuration. As for the thread timers above, you can readily get bar plot visualizations just by using UnicodePlots.","category":"page"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"using SubmatrixMethod, UnicodePlots\nusing ThreadPinning; pinthreads(:compact); # hide\nA = sprandsymposdef(1000, 0.01);\nsubmatrix_apply(inv, A, Threaded(show_distribution=true));","category":"page"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"We can set balance=true to enable balancing w.r.t. the total weight (sizes) of the submatrices each thread has to handle.","category":"page"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"submatrix_apply(inv, A, Threaded(balance=true, show_distribution=true));","category":"page"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"Note that the distribution of the sizes of the submatrices can we visualized with SubmatrixMethod.submatrix_sizes_hist.","category":"page"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"A = sprandsymposdef(10_000, 0.01);\nSubmatrixMethod.submatrix_sizes_hist(A);","category":"page"},{"location":"devel/benchmarking/#References","page":"Benchmarking","title":"References","text":"","category":"section"},{"location":"devel/benchmarking/#Index","page":"Benchmarking","title":"Index","text":"","category":"section"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"Pages   = [\"benchmarking.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"devel/benchmarking/#Functions","page":"Benchmarking","title":"Functions","text":"","category":"section"},{"location":"devel/benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"Modules = [SubmatrixMethod]\nPages   = [\"debugging.jl\"]","category":"page"},{"location":"devel/benchmarking/#SubmatrixMethod.disable_benchmarks-Tuple{}","page":"Benchmarking","title":"SubmatrixMethod.disable_benchmarks","text":"disable_benchmarks()\n\nDisables benchmarking.\n\nSee: enable_benchmarks\n\n\n\n\n\n","category":"method"},{"location":"devel/benchmarking/#SubmatrixMethod.enable_benchmarks-Tuple{}","page":"Benchmarking","title":"SubmatrixMethod.enable_benchmarks","text":"enable_benchmarks()\n\nEnables benchmarking. This affects all SubmatrixMethod.@bench macro applications.\n\nResults can be printed via SubmatrixMethod.print_benchmarks() and reset via SubmatrixMethod.reset_benchmarks().\n\nSee: disable_benchmarks\n\n\n\n\n\n","category":"method"},{"location":"devel/benchmarking/#SubmatrixMethod.print_benchmarks-Tuple{}","page":"Benchmarking","title":"SubmatrixMethod.print_benchmarks","text":"Print benchmark results.\n\nSee: enable_benchmarks\n\n\n\n\n\n","category":"method"},{"location":"devel/benchmarking/#SubmatrixMethod.print_submatrix_distribution-Tuple{Any, Any}","page":"Benchmarking","title":"SubmatrixMethod.print_submatrix_distribution","text":"Print the distribution of submatrices and their weights.\n\nIf UnicodePlots.jl is loaded (after using SubmatrixMethod), this function will produce a bar plot.\n\n\n\n\n\n","category":"method"},{"location":"devel/benchmarking/#SubmatrixMethod.print_thread_timers-Tuple{}","page":"Benchmarking","title":"SubmatrixMethod.print_thread_timers","text":"Print the current state of the thread timers.\n\nIf UnicodePlots.jl is loaded (after using SubmatrixMethod), this function will produce a bar plot.\n\n\n\n\n\n","category":"method"},{"location":"devel/benchmarking/#SubmatrixMethod.reset_benchmarks-Tuple{}","page":"Benchmarking","title":"SubmatrixMethod.reset_benchmarks","text":"Reset benchmark results.\n\n\n\n\n\n","category":"method"},{"location":"devel/benchmarking/#SubmatrixMethod.reset_thread_timers-Tuple{}","page":"Benchmarking","title":"SubmatrixMethod.reset_thread_timers","text":"Reset the thread timers to zero.\n\n\n\n\n\n","category":"method"},{"location":"devel/benchmarking/#SubmatrixMethod.@bench-Tuple{Any, Any}","page":"Benchmarking","title":"SubmatrixMethod.@bench","text":"Usage: @bench \"some description\" 3+3\n\nSee: enable_benchmarks\n\n\n\n\n\n","category":"macro"},{"location":"devel/guide/#Contribution-Guide","page":"Contribution Guide","title":"Contribution Guide","text":"","category":"section"},{"location":"devel/guide/#Conventions","page":"Contribution Guide","title":"Conventions","text":"","category":"section"},{"location":"devel/guide/#Source-code","page":"Contribution Guide","title":"Source code","text":"","category":"section"},{"location":"devel/guide/","page":"Contribution Guide","title":"Contribution Guide","text":"As indicated by the .JuliaFormatter.toml, we follow the BlueStyle for code formatting.\nEasiest way to make sure that code is formatted correctly is to use the autoformatting feature of the Julia VSCode extension.\nAlternatively, you can use JuliaFormatter.jl directly.\nThe user-provided input matrix is always labeled A.\nThe result matrix is always labeled R.","category":"page"},{"location":"devel/guide/#Documentation","page":"Contribution Guide","title":"Documentation","text":"","category":"section"},{"location":"devel/guide/","page":"Contribution Guide","title":"Contribution Guide","text":"Philosophically, we loosly try to implement the ideas put forward by David Laing in the documentation system a.k.a \"The Grand Unified Theory of Documentation\". TLDR:","category":"page"},{"location":"devel/guide/","page":"Contribution Guide","title":"Contribution Guide","text":"\"References\" should only contain technical descriptions (if examples, only very minimal ones)\n\"Explanations\" contains methods discussions / descriptions with formulas etc.\n\"Examples\" is for How-To guides\n(We don't really have Tutorials I guess?)","category":"page"},{"location":"refs/utility/#Utility","page":"Utility","title":"Utility","text":"","category":"section"},{"location":"refs/utility/#Index","page":"Utility","title":"Index","text":"","category":"section"},{"location":"refs/utility/","page":"Utility","title":"Utility","text":"Pages   = [\"utility.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"refs/utility/#References","page":"Utility","title":"References","text":"","category":"section"},{"location":"refs/utility/","page":"Utility","title":"Utility","text":"Modules = [SubmatrixMethod]\nPages   = [\"utility.jl\", \"sprandsymposdef.jl\"]","category":"page"},{"location":"refs/utility/#SubmatrixMethod.count_nz_per_column-Tuple{SparseArrays.SparseMatrixCSC}","page":"Utility","title":"SubmatrixMethod.count_nz_per_column","text":"Number of nonzero elements per column\n\n\n\n\n\n","category":"method"},{"location":"refs/utility/#SubmatrixMethod.density-Tuple{AbstractArray{<:Number}}","page":"Utility","title":"SubmatrixMethod.density","text":"Number of non-zero elements over the total number of elements.\n\n\n\n\n\n","category":"method"},{"location":"refs/utility/#SubmatrixMethod.distribute_evenly-Union{Tuple{T}, Tuple{Integer, AbstractVector{T}}} where T<:Integer","page":"Utility","title":"SubmatrixMethod.distribute_evenly","text":"distribute_evenly(nbins::Integer, weights::AbstractVector) -> bins, bin_weights\n\nDistributes the weights as evenly as possible across nbins bins.\n\nReturn values:\n\nbins: a vector of vectors containing the idcs of the entries in weights that have been assigned to each bin.\nbin_weights: the total weights of the bins.\n\n\n\n\n\n","category":"method"},{"location":"refs/utility/#SubmatrixMethod.find_nonempty_columns-Tuple{SparseArrays.SparseMatrixCSC}","page":"Utility","title":"SubmatrixMethod.find_nonempty_columns","text":"Returns the indices of non-empty columns, i.e. columns with at least one nonzero element.\n\n\n\n\n\n","category":"method"},{"location":"refs/utility/#SubmatrixMethod.inv!-Tuple{Any}","page":"Utility","title":"SubmatrixMethod.inv!","text":"inv!(M)\n\nIn-place matrix inversion. Overwrites the input matrix M with the result.\n\n\n\n\n\n","category":"method"},{"location":"refs/utility/#SubmatrixMethod.similar_zeroed-Union{Tuple{SparseArrays.SparseMatrixCSC{Tv}}, Tuple{Tv}} where Tv","page":"Utility","title":"SubmatrixMethod.similar_zeroed","text":"Creates a similar SparseMatrixCSC, i.e. with the same sparsity pattern, but with all non-zero values in S replaced by zeros.\n\n\n\n\n\n","category":"method"},{"location":"refs/utility/#SubmatrixMethod.sparsity-Tuple{AbstractArray{<:Number}}","page":"Utility","title":"SubmatrixMethod.sparsity","text":"Number of zero-valued elements over the total number of elements.\n\n\n\n\n\n","category":"method"},{"location":"refs/utility/#SubmatrixMethod.spectral_norm-Tuple{AbstractMatrix{<:Number}}","page":"Utility","title":"SubmatrixMethod.spectral_norm","text":"Computes the spectral norm of the input matrix:\n\nA_2=sqrtlambda_max left(A^H Aright)\n\ni.e. the square root of the maximal eigenvalue of A'*A.\n\n\n\n\n\n","category":"method"},{"location":"refs/utility/#SubmatrixMethod.sprandsymposdef-Tuple{Any, Any, Any}","page":"Utility","title":"SubmatrixMethod.sprandsymposdef","text":"sprandsymposdef(n,p,c)\n\nGenerates a sparse matrix of size (n,n) with the following properties:\n\nissymmetric\nisposdef\nhas approximately p * n^2 non-zero elements\nhas a condition number of exactly c\n\nWARNING: While it works okish for some inputs it can take ages to converge (if at all) for others!\n\nAlgorithm:\n\nCreates a diagonal positive-definite matrix with the desired condition number and applies random Jacobi rotations to it to create non-zero off-diagonal elements.\n\nReferences:\n\nThe function is inspired by MATLABs sprandsym(n,density,rc,kind=1).\n\n\n\n\n\n","category":"method"},{"location":"refs/utility/#SubmatrixMethod.sprandsymposdef-Tuple{Any, Any}","page":"Utility","title":"SubmatrixMethod.sprandsymposdef","text":"sprandsymposdef(n,p)\n\nGenerates a sparse matrix of size (n,n) with the following properties:\n\nissymmetric\nisposdef\nhas approximately p * n^2 non-zero elements\nhas a condition number of approximately c ≈ 1.\n\nAlgorithm:\n\nCreates a random sparse matrix (sprandn), symmetrizes it and makes it diagonally dominant by adding n*I to ensure positive definiteness.\n\nReferences:\n\nThe implementation of the function is inspired by this stackexchange thread.\n\n\n\n\n\n","category":"method"},{"location":"refs/submatrix/#Submatrix-Method","page":"Submatrix Method","title":"Submatrix Method","text":"","category":"section"},{"location":"refs/submatrix/#Index","page":"Submatrix Method","title":"Index","text":"","category":"section"},{"location":"refs/submatrix/","page":"Submatrix Method","title":"Submatrix Method","text":"Pages   = [\"submatrix.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"refs/submatrix/#References","page":"Submatrix Method","title":"References","text":"","category":"section"},{"location":"refs/submatrix/","page":"Submatrix Method","title":"Submatrix Method","text":"Modules = [SubmatrixMethod]\nPages   = [\"submatrix.jl\"]","category":"page"},{"location":"refs/submatrix/#SubmatrixMethod.construct_submatrix-Tuple{AbstractMatrix, Any}","page":"Submatrix Method","title":"SubmatrixMethod.construct_submatrix","text":"construct_submatrix(A, j) -> submatrix, indices\n\nConstruct the j-th submatrix form the input matrix A.\n\n\n\n\n\n","category":"method"},{"location":"refs/submatrix/#SubmatrixMethod.submatrix_apply","page":"Submatrix Method","title":"SubmatrixMethod.submatrix_apply","text":"submatrix_apply(f, A[, lc])\n\nUses the submatrix method to approximately compute f(A), i.e. the application of the matrix function f to the input matrix A.\n\nThe input matrix A must be\n\npositive definite (check with isposdef),\nsymmetric (check with issymmetric).\n\nand should be\n\nsparse (check with sparsity or density).\n\nA LaunchConfiguration, such as Serial or Threaded, which specifies the modus operandi can be provided as a third argument (lc).\n\n\n\n\n\n","category":"function"},{"location":"refs/submatrix/#SubmatrixMethod.submatrix_computation!-Tuple{AbstractMatrix, Any, AbstractMatrix, Any}","page":"Submatrix Method","title":"SubmatrixMethod.submatrix_computation!","text":"submatrix_computation!(R, f, A, j)\n\nThis is the \"computation kernel\". Constructs the j-th submatrix from the input matrix A, applies the matrix function f to it, and fills the corresponding column of the result matrix R.\n\n\n\n\n\n","category":"method"},{"location":"refs/submatrix/#SubmatrixMethod.submatrix_computation_inplace!-Tuple{AbstractMatrix, Any, AbstractMatrix, Any}","page":"Submatrix Method","title":"SubmatrixMethod.submatrix_computation_inplace!","text":"submatrix_computation_inplace!(R, f_inplace, A, j)\n\nThis is the \"computation kernel\". Constructs the j-th submatrix from the input matrix A, applies the matrix function f_inplace to it (in-place), and fills the corresponding column of the result matrix R.\n\n\n\n\n\n","category":"method"},{"location":"explanations/smmethod/#submatrixmethod","page":"Submatrix Method","title":"Submatrix Method","text":"","category":"section"},{"location":"explanations/smmethod/","page":"Submatrix Method","title":"Submatrix Method","text":"<figure>\n    <img src=\"../../assets/imgs/smmethod.svg\" width=\"80%\"/>\n    <figcaption>Fig.1 – Illustration of the submatrix method.</figcaption>\n</figure>","category":"page"},{"location":"explanations/smmethod/#Strategy","page":"Submatrix Method","title":"Strategy","text":"","category":"section"},{"location":"explanations/smmethod/","page":"Submatrix Method","title":"Submatrix Method","text":"We consider a sparse, symmetric, n times n, input matrix A for which we want to compute the matrix function f(A). The strategy of the submatrix method is simple: instead of computing f(A) directly, we","category":"page"},{"location":"explanations/smmethod/","page":"Submatrix Method","title":"Submatrix Method","text":"decompose A into n submatrices S_i,\napply f to each submatrix,\nand approximate f(A) from the submatrix results f(S_i) (see Fig. 1).","category":"page"},{"location":"explanations/smmethod/","page":"Submatrix Method","title":"Submatrix Method","text":"Specifically, a submatrix S_i is associated with the i-th column of A and is constructed as follows. First, we find the row indices gamma of all the non-zero elements in column i. Next, we extract those elements from A that correspond to all pairs that we can form from gamma and \"glue them together\" to build the submatrix S_i. Note that while S_i is associated with column i, in particular its non-zero entries, it still contains elements from other columns as well.","category":"page"},{"location":"explanations/smmethod/","page":"Submatrix Method","title":"Submatrix Method","text":"Once we have the submatrices S_i, we compute f(S_i) for each of them. Afterwards, the desired result f(A) is approximated by the result matrix R which has the same sparsity pattern as A - that is the count and position of non-zero entries is preserved - but whose values in a column i are given by the corresponding column tildei of f(S_i) (see Fig. 1). Hence, each submatrix computation produces one column of the result matrix.","category":"page"},{"location":"explanations/smmethod/#Complexity","page":"Submatrix Method","title":"Complexity","text":"","category":"section"},{"location":"explanations/smmethod/","page":"Submatrix Method","title":"Submatrix Method","text":"TODO","category":"page"},{"location":"explanations/smmethod/#Paralellization","page":"Submatrix Method","title":"Paralellization","text":"","category":"section"},{"location":"explanations/smmethod/","page":"Submatrix Method","title":"Submatrix Method","text":"TODO","category":"page"},{"location":"explanations/smmethod/#References","page":"Submatrix Method","title":"References","text":"","category":"section"},{"location":"explanations/smmethod/","page":"Submatrix Method","title":"Submatrix Method","text":"A Massively Parallel Algorithm for the Approximate Calculation of Inverse p-th Roots of Large Sparse Matrices   Michael Lass, Stephan Mohr, Hendrik Wiebeler, Thomas D. Kühne, Christian Plessl   GitHub repository: https://github.com/pc2/SubmatrixMethod","category":"page"},{"location":"explanations/smmethod/","page":"Submatrix Method","title":"Submatrix Method","text":"A Submatrix-Based Method for Approximate Matrix Function Evaluation in the Quantum Chemistry Code CP2K   Michael Lass, Robert Schade, Thomas D. Kühne, Christian Plessl arXiv: https://arxiv.org/abs/2004.10811","category":"page"},{"location":"refs/io/#IO","page":"IO","title":"IO","text":"","category":"section"},{"location":"refs/io/","page":"IO","title":"IO","text":"Writing, reading, and memory mapping SparseMatrixCSC to and from disk.","category":"page"},{"location":"refs/io/","page":"IO","title":"IO","text":"using SubmatrixMethod, SparseArrays","category":"page"},{"location":"refs/io/#HDF5","page":"IO","title":"HDF5","text":"","category":"section"},{"location":"refs/io/","page":"IO","title":"IO","text":"Functionality for writing, reading, or memory mapping a SparseMatrixCSC[Tv, Ti} into or from a specific path in a HDF5 file. For memory mapping, the value type (Tv) must be isbitstype (e.g Float64, Float32. or ComplexF64).","category":"page"},{"location":"refs/io/","page":"IO","title":"IO","text":"We'll just write / read the fields of the SparseMatrixCSC into / from separate datasets under the given path.","category":"page"},{"location":"refs/io/","page":"IO","title":"IO","text":"Example:","category":"page"},{"location":"refs/io/","page":"IO","title":"IO","text":"S = sprand(100, 100, 0.001);\nSubmatrixMethod.write_hdf5(\"mymatrix.h5\", \"S\", S)\nisfile(\"mymatrix.h5\")\nT = SubmatrixMethod.read_hdf5(\"mymatrix.h5\", \"S\");\nS == T\nR = SubmatrixMethod.read_hdf5(\"mymatrix.h5\", \"S\"; mmap=true);\nR == T\nrm(\"mymatrix.h5\") # hide","category":"page"},{"location":"refs/io/#Single-binary-file","page":"IO","title":"Single binary file","text":"","category":"section"},{"location":"refs/io/","page":"IO","title":"IO","text":"We define our own Binary Compressed Sparse Column (BCSC) format for storing a SparseMatrixCSC{Tv, Ti} on disk. The value type Tv must be a regular floating point type (e.g. Float64 or Float32) and the index type Ti must be a regular integer type (e.g. Int64 or Int128).","category":"page"},{"location":"refs/io/","page":"IO","title":"IO","text":"\"Definition\" of the format based on the SparseMatrixCSC data structure:","category":"page"},{"location":"refs/io/","page":"IO","title":"IO","text":"# header\nwrite(f, sizeof(Tv))\nwrite(f, sizeof(Ti))\nwrite(f, length(S.colptr))\nwrite(f, length(S.rowval))\nwrite(f, length(S.nzval))\n# data\nwrite(f, S.m)\nwrite(f, S.n)\nwrite(f, S.colptr)\nwrite(f, S.rowval)\nwrite(f, S.nzval)","category":"page"},{"location":"refs/io/","page":"IO","title":"IO","text":"Example:","category":"page"},{"location":"refs/io/","page":"IO","title":"IO","text":"S = sprand(100, 100, 0.001);\nSubmatrixMethod.write_bcsc(\"mymatrix.bcsc\", S)\nisfile(\"mymatrix.bcsc\")\nT = SubmatrixMethod.read_bcsc(\"mymatrix.bcsc\");\nS == T\nR = SubmatrixMethod.read_bcsc(\"mymatrix.bcsc\"; mmap=true);\nR == T\nrm(\"mymatrix.bcsc\") # hide","category":"page"},{"location":"refs/io/","page":"IO","title":"IO","text":"warning: Warning\nAs for now, we don't care about endianness etc. which means that, in general, our format is not portable! As an alternative, consider using HDF5 instead.","category":"page"},{"location":"refs/io/#Three-binary-files","page":"IO","title":"Three binary files","text":"","category":"section"},{"location":"refs/io/","page":"IO","title":"IO","text":"The fields colptr, rowval, and nzval of the SparseMatrixCSC are simply stored in separate binary files with the file extensions .colptr, .rowval, and .nzval, respectively.","category":"page"},{"location":"refs/io/","page":"IO","title":"IO","text":"Example:","category":"page"},{"location":"refs/io/","page":"IO","title":"IO","text":"S = sprand(100, 100, 0.001);\nSubmatrixMethod.write_three_files(\"mymatrix\", S)\nfilter(startswith(\"mymatrix\"), readdir())\nT = SubmatrixMethod.read_three_files(\"mymatrix\");\nS == T\nR = SubmatrixMethod.read_three_files(\"mymatrix\"; mmap=true);\nR == T\nrm.(filter(startswith(\"mymatrix\"), readdir())) # hide","category":"page"},{"location":"refs/io/#Index","page":"IO","title":"Index","text":"","category":"section"},{"location":"refs/io/","page":"IO","title":"IO","text":"Pages   = [\"io.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"refs/io/#References","page":"IO","title":"References","text":"","category":"section"},{"location":"refs/io/","page":"IO","title":"IO","text":"Modules = [SubmatrixMethod]\nPages   = [\"io.jl\"]","category":"page"},{"location":"refs/io/#SubmatrixMethod.read_bcsc-Tuple{AbstractString}","page":"IO","title":"SubmatrixMethod.read_bcsc","text":"Creates a S::SparseMatrixCSC from a binary file in BCSC format, e.g. created using write_bcsc.\n\nKeyword arguments:\n\nmmap (default: false): If true, the data of the arrays colptr, rowval, and nzval within the returned SparseMatrixCSC is linked to the data in the binary file on disk (memory mapping).\n\nSee: write_bcsc\n\n\n\n\n\n","category":"method"},{"location":"refs/io/#SubmatrixMethod.read_hdf5-Tuple{AbstractString, AbstractString}","page":"IO","title":"SubmatrixMethod.read_hdf5","text":"Creates a S::SparseMatrixCSC from the dataset at path in the HDF5 file fname, which should have been created using write_hdf5.\n\nKeyword arguments:\n\nmmap (default: false): If true, the data of the arrays colptr, rowval, and nzval within the returned SparseMatrixCSC is linked to the data in the HDF5 file on disk (memory mapping).\n\nSee: write_hdf5\n\n\n\n\n\n","category":"method"},{"location":"refs/io/#SubmatrixMethod.read_three_files","page":"IO","title":"SubmatrixMethod.read_three_files","text":"Creates a S::SparseMatrixCSC by reading the binary data of the fields from the files prefix.colptr, prefix.rowval, and prefix.nzval.\n\nImportant note: This functions assumes that the sparse matrix is square, i.e. that m == n!\n\nKeyword arguments:\n\nmmap (default: false): If true, the data of the arrays colptr, rowval, and nzval within the returned SparseMatrixCSC is linked to the respective binary files on disk (memory mapping).\n\nSee: write_three_files\n\n\n\n\n\n","category":"function"},{"location":"refs/io/#SubmatrixMethod.read_txt","page":"IO","title":"SubmatrixMethod.read_txt","text":"Read in txt files produced by Matlab (see Michael's original implementation) and return a SparseMatrixCSC.\n\n\n\n\n\n","category":"function"},{"location":"refs/io/#SubmatrixMethod.write_bcsc-Union{Tuple{Ti}, Tuple{Tv}, Tuple{AbstractString, SparseArrays.SparseMatrixCSC{Tv, Ti}}} where {Tv, Ti}","page":"IO","title":"SubmatrixMethod.write_bcsc","text":"Writes a SparseMatrixCSC to file in our custom BCSC (Binary Compressed Sparse Column) format.\n\nSee: read_bcsc\n\n\n\n\n\n","category":"method"},{"location":"refs/io/#SubmatrixMethod.write_hdf5-Tuple{AbstractString, AbstractString, SparseArrays.SparseMatrixCSC}","page":"IO","title":"SubmatrixMethod.write_hdf5","text":"Writes a SparseMatrixCSC into the HDF5 file fname under path. Will create the file if it doesn't exist yet.\n\nSee: read_hdf5\n\n\n\n\n\n","category":"method"},{"location":"refs/io/#SubmatrixMethod.write_three_files-Tuple{AbstractString, SparseArrays.SparseMatrixCSC}","page":"IO","title":"SubmatrixMethod.write_three_files","text":"Writes S::SparseMatrixCSC to three binary files prefix.colptr, prefix.rowval, and prefix.nzval storing the respective fieldvalues of the sparse matrix.\n\nSee: read_three_files\n\n\n\n\n\n","category":"method"},{"location":"#SubmatrixMethod.jl","page":"SubmatrixMethod","title":"SubmatrixMethod.jl","text":"","category":"section"},{"location":"","page":"SubmatrixMethod","title":"SubmatrixMethod","text":"Approximately compute matrix functions of matrices by using the submatrix method.","category":"page"},{"location":"","page":"SubmatrixMethod","title":"SubmatrixMethod","text":"The input matrix must be","category":"page"},{"location":"","page":"SubmatrixMethod","title":"SubmatrixMethod","text":"positive definite (check with isposdef),\nsymmetric (check with issymmetric).","category":"page"},{"location":"","page":"SubmatrixMethod","title":"SubmatrixMethod","text":"and should be","category":"page"},{"location":"","page":"SubmatrixMethod","title":"SubmatrixMethod","text":"sparse (check with sparsity or density).","category":"page"},{"location":"#Installation","page":"SubmatrixMethod","title":"Installation","text":"","category":"section"},{"location":"","page":"SubmatrixMethod","title":"SubmatrixMethod","text":"You can simply add SubmatrixMethod.jl to your Julia environment with the command","category":"page"},{"location":"","page":"SubmatrixMethod","title":"SubmatrixMethod","text":"] add https://git.uni-paderborn.de/pc2/julia/submatrixmethod.jl","category":"page"},{"location":"","page":"SubmatrixMethod","title":"SubmatrixMethod","text":"note: Note\nThe minimal required Julia version is 1.6 but we recommend using Julia ≥ 1.7.","category":"page"},{"location":"#TLDR","page":"SubmatrixMethod","title":"TLDR","text":"","category":"section"},{"location":"","page":"SubmatrixMethod","title":"SubmatrixMethod","text":"using SubmatrixMethod\n\n# sparse, symmetric, random, positive definite matrix of\n# size 1000 x 1000 with density around 0.05.\nA = sprandsymposdef(1000, 0.05)\n\nX = inv(Matrix(A))\nY = submatrix_apply(inv, A)\n\nmaximum(abs.(X .- Y) ≤ 1e-7 # true","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"EditURL = \"https://git.uni-paderborn.de/pc2/julia/submatrixmethod.jl/blob/main/docs/docs/src/examples/matrix_inv.jl\"","category":"page"},{"location":"examples/matrix_inv/#Speeding-up-Matrix-Inversion","page":"Matrix Inversion","title":"Speeding up Matrix Inversion","text":"","category":"section"},{"location":"examples/matrix_inv/#Regular-inversion","page":"Matrix Inversion","title":"Regular inversion","text":"","category":"section"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"First, we need to generate a random input matrix M that we want to invert. However, since the submatrix method expects a sparse symmetric positive definite matrix, we can't just use rand. Instead, we use the utility function sprandsymposdef to generate our input matrix.","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"using SubmatrixMethod\nSubmatrixMethod.disable_benchmarks() # hide\nusing MKL, LinearAlgebra # hide\nBLAS.set_num_threads(1) # hide\nM = sprandsymposdef(1000, 0.001)","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"Note that M isn't just sparse in the value sense but actually a SparseMatrixCSC datastructure.","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"typeof(M)","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"If we try to naively invert this matrix, i.e. calling inv(M), Julia will throw an error, reminding us of the fact that the inverse of a sparse matrix is generally dense. To circumvent this error, we first need to convert M to a dense Matrix{Float64} first.","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"Mdense = Matrix(M);\nnothing #hide","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"Now, inv(M) does what it's supposed to do.","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"using LinearAlgebra, Test\n@test inv(Mdense) * Mdense ≈ I","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"Alright, let's load BenchmarkTools.jl and benchmark how long the conventional inversion takes. This will serve as a baseline that we can compare to the submatrix method.","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"using BenchmarkTools\n@btime inv($Mdense);\nnothing #hide","category":"page"},{"location":"examples/matrix_inv/#Submatrix-method","page":"Matrix Inversion","title":"Submatrix method","text":"","category":"section"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"Using the function submatrix_apply by SubmatrixMethod.jl, we can get a (good) approximation of inv(Mdense) via submatrix_apply(inv, Mdense).","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"M̃inv = submatrix_apply(inv, Mdense)\nMinv = inv(Mdense)\nmaximum(abs.(M̃inv .- Minv))","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"However, note that the computation based on the submatrix method is much faster","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"@btime submatrix_apply($inv, $Mdense);\nnothing #hide","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"And it is even faster if we provide the sparse matrix (SparseMatrixCSC) directly","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"@btime submatrix_apply($inv, $M);\nnothing #hide","category":"page"},{"location":"examples/matrix_inv/#Multithreading","page":"Matrix Inversion","title":"Multithreading","text":"","category":"section"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"Depending on the size/sparsity of the input matrix (see Scaling), we can sometimes speed things up even further by enabling the multithreading functionality of SubmatrixMethod.jl. Of course, this only works if we've started Julia with multiple threads in the first place.","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"Threads.nthreads()","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"To avoid conflicts with BLAS's built-in multithreading, it is generally recommended to set the number of BLAS threads to one.","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"BLAS.set_num_threads(1)","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"Also, it is generally a good idea to pin Julia threads to different cores (preferrably within a NUMA domain). Here, we use the package ThreadPinning.jl to implement a compact pinning strategy.","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"using ThreadPinning\npinthreads(:compact)","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"Alright, here comes a benchmark that shows a case where multithreading gives a decent speedup.","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"M = sprandsymposdef(1000, 0.01)\n@btime submatrix_apply($inv, $M, $(Serial()));\n@btime submatrix_apply($inv, $M, $(Threaded()));\nnothing #hide","category":"page"},{"location":"examples/matrix_inv/#Scaling","page":"Matrix Inversion","title":"Scaling","text":"","category":"section"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"As a function of the density of the input matrix (and for various sizes)\nAs a function of the size of the input matrix (and for various densities)\nAs a function of the number of Julia / BLAS threads","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"So much about speeding up matrix inversion with the submatrix method. See you in the next tutorial!","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"","category":"page"},{"location":"examples/matrix_inv/","page":"Matrix Inversion","title":"Matrix Inversion","text":"This page was generated using Literate.jl.","category":"page"},{"location":"refs/lc/#Launch-Configurations","page":"Launch Configurations","title":"Launch Configurations","text":"","category":"section"},{"location":"refs/lc/#Index","page":"Launch Configurations","title":"Index","text":"","category":"section"},{"location":"refs/lc/","page":"Launch Configurations","title":"Launch Configurations","text":"Pages   = [\"lc.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"refs/lc/#References","page":"Launch Configurations","title":"References","text":"","category":"section"},{"location":"refs/lc/","page":"Launch Configurations","title":"Launch Configurations","text":"Modules = [SubmatrixMethod]\nPages   = [\"lc.jl\"]","category":"page"},{"location":"refs/lc/#SubmatrixMethod.LaunchConfiguration","page":"Launch Configurations","title":"SubmatrixMethod.LaunchConfiguration","text":"An abstract launch configuration for submatrix_apply. See subtypes(LaunchConfiguration) for a list of available launch configurations.\n\n\n\n\n\n","category":"type"},{"location":"refs/lc/#SubmatrixMethod.Serial","page":"Launch Configurations","title":"SubmatrixMethod.Serial","text":"No parallelism. (BLAS might be parallelized, of course.)\n\nFields / keyword arguments:\n\ninplace (default: false): if true, expects that f is an in-place matrix function that overwrites the input matrix with the result, i.e. inv! instead of inv, for example.\n\n\n\n\n\n","category":"type"},{"location":"refs/lc/#SubmatrixMethod.SerialMPI","page":"Launch Configurations","title":"SubmatrixMethod.SerialMPI","text":"Use multiprocessing via MPI. On each MPI worker, run things in serial.\n\nFields / keyword arguments:\n\ninplace (default: false): if true, expects that f is an in-place matrix function that overwrites the input matrix with the result, i.e. inv! instead of inv, for example.\n\n\n\n\n\n","category":"type"},{"location":"refs/lc/#SubmatrixMethod.Threaded","page":"Launch Configurations","title":"SubmatrixMethod.Threaded","text":"Multithreading.\n\nFields / keyword arguments:\n\nmode (default: :threads): If :spawn, @spawn is used, i.e. tasks and dynamic load balancing. If :batch, Polyester's @batch is used, i.e. no load balancing. Else, @threads :static is used, i.e. no load balancing.\nnthreads (default: Threads.nthreads()): For some modes, this allows one to set the number of used Julia threads. Threads.nthreads() is the default and an upper bound.\nbalance (default: false): if true, we distribute submatrices as evenly as possible (w.r.t. their size) across threads. Not available for mode = :spawn.\nshow_distribution (default: false): if true, we print the distribution of submatrices and their weight (i.e. size) across threads. If UnicodePlots.jl is loaded, bar plots are produced.\ninplace (default: false): if true, expects that f is an in-place matrix function that overwrites the input matrix with the result, i.e. inv! instead of inv, for example.\n\n\n\n\n\n","category":"type"}]
}
